{
 "cells": [
  {
   "cell_type": "raw",
   "id": "737b4689-45ad-4327-8721-55301cede4c0",
   "metadata": {},
   "source": [
    "üß† Main Goal (Objectif principal de ce travail)\n",
    "üîç Objectif du script :\n",
    "Analyser automatiquement une page web pour :\n",
    "\n",
    "R√©cup√©rer le titre, le contenu textuel nettoy√© et tous les liens d'une page.\n",
    "\n",
    "Filtrer les liens les plus pertinents pour une brochure d‚Äôentreprise (comme About, Company, Careers).\n",
    "\n",
    "Utiliser un LLM (anciennement GPT via OpenAI, maintenant LLaMA 3.2 via Ollama) pour identifier les bons liens.\n",
    "\n",
    "Optionnellement, afficher ou stocker le contenu des pages s√©lectionn√©es.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaccd21-d068-4685-abd1-272ebc8b64c9",
   "metadata": {},
   "source": [
    "‚úÖ üß† Code complet : Scraper une page web, extraire les liens pertinents avec LLaMA 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faeb657a-e6c4-4100-925d-829fd4b7f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from typing import List\n",
    "from bs4 import BeautifulSoup\n",
    "import ollama\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826b8aa2-5108-401a-aae8-eda153e0f56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers pour √©viter les blocages par certains sites\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                  \"(KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84b55305-c540-4482-933f-62d43e9f52b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Classe Website : pour extraire le contenu, le titre et les liens\n",
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=5)\n",
    "            response.raise_for_status()\n",
    "            self.body = response.content\n",
    "            soup = BeautifulSoup(self.body, 'html.parser')\n",
    "            self.title = soup.title.string.strip() if soup.title else \"No title found\"\n",
    "\n",
    "            if soup.body:\n",
    "                for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                    irrelevant.decompose()\n",
    "                self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "            else:\n",
    "                self.text = \"\"\n",
    "\n",
    "            # Extraire tous les liens, relatifs et absolus\n",
    "            links = [link.get('href') for link in soup.find_all('a')]\n",
    "            self.links = [\n",
    "                urljoin(self.url, link)\n",
    "                for link in links\n",
    "                if link and not link.startswith(\"mailto:\") and not link.startswith(\"javascript:\")\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {url}: {e}\")\n",
    "            self.title = \"Error\"\n",
    "            self.text = \"\"\n",
    "            self.links = []\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\"\n",
    "        #‚ñ∂Ô∏è Elle retourne une cha√Æne lisible contenant le titre et le texte principal de la page.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658d3441-6935-49f9-b83d-5da3ebe865ad",
   "metadata": {},
   "source": [
    "\n",
    "### ‚ñ∂Ô∏è R√¥le :\n",
    "\n",
    "Cette classe repr√©sente un site web donn√© et permet :\n",
    "\n",
    "* de r√©cup√©rer le **titre** de la page,\n",
    "* le **texte nettoy√©** (sans scripts, images, etc.),\n",
    "* et **tous les liens** pr√©sents dans la page.\n",
    "\n",
    "### üì¶ Attributs :\n",
    "\n",
    "* `self.url` : l'URL du site.\n",
    "* `self.body` : le code HTML brut de la page.\n",
    "* `self.title` : le titre de la page (`<title>` dans le HTML).\n",
    "* `self.text` : le texte visible (nettoy√©).\n",
    "* `self.links` : la liste des liens cliquables (`<a href=\"...\">`), convertis en **liens absolus** avec `urljoin`.\n",
    "\n",
    "### üîÅ M√©thode :\n",
    "\n",
    "```python\n",
    "def get_contents(self):\n",
    "    return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\"\n",
    "```\n",
    "\n",
    "‚ñ∂Ô∏è Elle retourne une **cha√Æne lisible** contenant le **titre** et le **texte** principal de la page.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a28ee0-bdd0-443e-b8db-c5946786dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction pour interroger LLaMA 3.2 via Ollama pour filtrer les bons liens\n",
    "def get_relevant_links_with_llama3(url: str, links: List[str]) -> dict:\n",
    "    prompt = f\"\"\"You are provided with a list of links found on the website {url}.\n",
    "Please choose the links relevant to include in a company brochure (e.g. About, Company, Careers, Jobs).\n",
    "Do NOT include links like Privacy Policy, Terms of Service, Contact, mailto, login, or similar.\n",
    "Return only a JSON object like this:\n",
    "\n",
    "{{\n",
    "  \"links\": [\n",
    "    {{\"type\": \"about page\", \"url\": \"https://example.com/about\"}},\n",
    "    {{\"type\": \"careers page\", \"url\": \"https://example.com/careers\"}}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "List of links:\n",
    "{chr(10).join(links)}\n",
    "\"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.2\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    content = response[\"message\"][\"content\"]\n",
    "\n",
    "    # Afficher la r√©ponse brute (utile pour debug)\n",
    "    print(\"üì® Raw LLaMA response:\\n\", content)\n",
    "\n",
    "    # Extraire le JSON uniquement (entre { ... })\n",
    "    try:\n",
    "        json_match = re.search(r\"\\{[\\s\\S]*?\\}\", content)\n",
    "        if json_match:\n",
    "            json_text = json_match.group(0)\n",
    "            try:\n",
    "                return json.loads(json_text)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"‚ö†Ô∏è JSON decoding failed: {e}\")\n",
    "                # Essayer de corriger un JSON malform√©\n",
    "                corrected = json_text.replace(\"‚Äù\", \"\\\"\").replace(\"‚Äú\", \"\\\"\").replace(\"‚Äô\", \"'\")\n",
    "                corrected = re.sub(r'\":\\s*\"(https?:[^\"]+)\"([^,\\}])', r'\": \"\\1\",\\2', corrected)\n",
    "                return json.loads(corrected)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Unexpected failure while parsing JSON:\", e)\n",
    "\n",
    "    return {\"links\": []}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc14939f-c6df-491a-ad7e-eef41a3beac0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîπ 2. `get_relevant_links_with_llama3(url, links)`\n",
    "\n",
    "```python\n",
    "def get_relevant_links_with_llama3(url: str, links: List[str]) -> dict:\n",
    "```\n",
    "\n",
    "### ‚ñ∂Ô∏è R√¥le :\n",
    "\n",
    "Cette fonction utilise **LLaMA 3.2 (via Ollama)** pour **filtrer automatiquement les liens pertinents** (comme \"About\", \"Company\", \"Careers\") parmi une liste.\n",
    "\n",
    "### ‚öôÔ∏è √âtapes :\n",
    "\n",
    "1. **Construit un prompt** qui contient :\n",
    "\n",
    "   * des instructions claires,\n",
    "   * un exemple de format JSON attendu,\n",
    "   * la liste des liens trouv√©s sur le site.\n",
    "2. Envoie ce prompt √† **Ollama** avec `ollama.chat(...)`.\n",
    "3. R√©cup√®re la **r√©ponse brute**.\n",
    "4. Utilise une **expression r√©guli√®re** (`re.search`) pour extraire uniquement le JSON `{...}`.\n",
    "5. Essaie de parser ce JSON avec `json.loads`.\n",
    "6. S‚Äôil y a une erreur de format, essaie de **corriger automatiquement** les erreurs classiques (guillemets typographiques, virgules manquantes, etc.).\n",
    "\n",
    "### ‚ñ∂Ô∏è Retour :\n",
    "\n",
    "Un dictionnaire Python avec une structure comme :\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"links\": [\n",
    "    {\"type\": \"about page\", \"url\": \"https://site.com/about\"},\n",
    "    {\"type\": \"careers page\", \"url\": \"https://site.com/jobs\"}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9e3be3-eea5-40d1-991e-8dfcc603bcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction principale qui combine tout\n",
    "def get_all_details(url: str) -> str:\n",
    "    result = f\"Landing page: {url}\\n\"\n",
    "    landing = Website(url)\n",
    "    result += landing.get_contents()\n",
    "\n",
    "    print(f\"üîó Extracted {len(landing.links)} links.\")\n",
    "    filtered = get_relevant_links_with_llama3(url, landing.links)\n",
    "\n",
    "    for link in filtered.get(\"links\", []):\n",
    "        print(f\"‚úÖ Found relevant link: {link['type']} - {link['url']}\")\n",
    "        page = Website(link[\"url\"])\n",
    "        result += f\"\\n\\n{link['type'].capitalize()}:\\n\"\n",
    "        result += page.get_contents()\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f485db1-2cd1-43e4-bb44-cec3975873df",
   "metadata": {},
   "source": [
    "## üîπ 3. `get_all_details(url)`\n",
    "\n",
    "```python\n",
    "def get_all_details(url: str) -> str:\n",
    "```\n",
    "\n",
    "### ‚ñ∂Ô∏è R√¥le :\n",
    "\n",
    "Fonction principale qui **orchestre tout le processus** :\n",
    "\n",
    "1. Analyse la page d‚Äôaccueil du site (`Website(url)`).\n",
    "2. R√©cup√®re **tous les liens** sur la page d‚Äôaccueil.\n",
    "3. Envoie les liens √† **LLaMA** pour d√©tecter ceux pertinents pour une brochure.\n",
    "4. Pour chaque lien s√©lectionn√©, r√©cup√®re et affiche son contenu.\n",
    "5. Retourne une **grande cha√Æne de texte** regroupant tous les r√©sultats (titre, texte principal, contenus des pages secondaires).\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Exemple d‚Äôutilisation finale :\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://huggingface.co\"\n",
    "    output = get_all_details(url)\n",
    "    print(output)\n",
    "```\n",
    "\n",
    "### ‚ñ∂Ô∏è Que fait ce bloc ?\n",
    "\n",
    "* Il appelle la fonction `get_all_details(...)` pour un site web r√©el.\n",
    "* Affiche l‚Äôensemble des textes r√©cup√©r√©s (accueil + pages utiles).\n",
    "* Peut √™tre remplac√© par une interface utilisateur ou sauvegard√© dans un fichier.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "169187e4-bbe6-463f-9e96-c19d8ce8341a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Extracted 80 links.\n",
      "üì® Raw LLaMA response:\n",
      " {\n",
      "  \"links\": [\n",
      "    {\"type\": \"about page\", \"url\": \"https://huggingface.co/about\"},\n",
      "    {\"type\": \"company page\", \"url\": \"https://huggingface.co/brand\"},\n",
      "    {\"type\": \"careers page\", \"url\": \"https://apply.workable.com/huggingface/\"},\n",
      "    {\"type\": \"jobs page\", \"url\": \"https://apply.workable.com/huggingface/\"}\n",
      "  ]\n",
      "}\n",
      "\n",
      "Note: I couldn't find any specific information about the company's jobs page, but Workable is a popular platform for job postings. If you need to include a link that's not present in the provided list, please let me know.\n",
      "\n",
      "Also, note that some links were excluded from the final result as they didn't fit into the categories \"About\", \"Company\", or \"Careers\".\n",
      "‚ö†Ô∏è JSON decoding failed: Expecting ',' delimiter: line 3 column 66 (char 80)\n",
      "‚ùå Unexpected failure while parsing JSON: Expecting ',' delimiter: line 3 column 66 (char 80)\n",
      "\n",
      "\n",
      "=== R√©sultat final ===\n",
      "\n",
      "Landing page: https://huggingface.co\n",
      "Webpage Title:\n",
      "Hugging Face ‚Äì The AI community building the future.\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "black-forest-labs/FLUX.1-Kontext-dev\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "12.9k\n",
      "‚Ä¢\n",
      "1.04k\n",
      "tencent/Hunyuan-A13B-Instruct\n",
      "Updated\n",
      "about 7 hours ago\n",
      "‚Ä¢\n",
      "578\n",
      "google/gemma-3n-E4B-it\n",
      "Updated\n",
      "4 days ago\n",
      "‚Ä¢\n",
      "5.55k\n",
      "‚Ä¢\n",
      "307\n",
      "OmniGen2/OmniGen2\n",
      "Updated\n",
      "7 days ago\n",
      "‚Ä¢\n",
      "20.1k\n",
      "‚Ä¢\n",
      "269\n",
      "google/magenta-realtime\n",
      "Updated\n",
      "8 days ago\n",
      "‚Ä¢\n",
      "418\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "8.92k\n",
      "8.92k\n",
      "DeepSite v2\n",
      "üê≥\n",
      "Generate any application with DeepSeek\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "322\n",
      "322\n",
      "OmniGen2\n",
      "üëÄ\n",
      "OmniGen2: Unified Image Understanding and Generation.\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "284\n",
      "284\n",
      "FLUX.1 Kontext\n",
      "‚ö°\n",
      "Kontext image editing on FLUX[dev]\n",
      "Running\n",
      "939\n",
      "939\n",
      "Sparc3D\n",
      "üèÉ\n",
      "Next-Gen High-Resolution 3D Model Generation\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "260\n",
      "260\n",
      "Self Forcing Wan 2.1\n",
      "üé•\n",
      "Real-time video generation\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "fka/awesome-chatgpt-prompts\n",
      "Updated\n",
      "Jan 6\n",
      "‚Ä¢\n",
      "22.9k\n",
      "‚Ä¢\n",
      "8.1k\n",
      "facebook/seamless-interaction\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "1\n",
      "‚Ä¢\n",
      "53\n",
      "FreedomIntelligence/ShareGPT-4o-Image\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "75\n",
      "‚Ä¢\n",
      "50\n",
      "institutional/institutional-books-1.0\n",
      "Updated\n",
      "14 days ago\n",
      "‚Ä¢\n",
      "38.2k\n",
      "‚Ä¢\n",
      "205\n",
      "HuggingFaceFW/fineweb-2\n",
      "Updated\n",
      "4 days ago\n",
      "‚Ä¢\n",
      "38.3k\n",
      "‚Ä¢\n",
      "532\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Compute\n",
      "Deploy on optimized\n",
      "Inference Endpoints\n",
      "or update your\n",
      "Spaces applications\n",
      "to a GPU in a few clicks.\n",
      "View pricing\n",
      "Starting at $0.60/hour for GPU\n",
      "Enterprise\n",
      "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
      "\t\t\tdedicated support.\n",
      "Getting started\n",
      "Starting at $20/user/month\n",
      "Single Sign-On\n",
      "Regions\n",
      "Priority Support\n",
      "Audit Logs\n",
      "Resource Groups\n",
      "Private Datasets Viewer\n",
      "More than 50,000 organizations are using Hugging Face\n",
      "Ai2\n",
      "Enterprise\n",
      "non-profit\n",
      "‚Ä¢\n",
      "766 models\n",
      "‚Ä¢\n",
      "3.51k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "2.17k models\n",
      "‚Ä¢\n",
      "6.64k followers\n",
      "Amazon\n",
      "company\n",
      "‚Ä¢\n",
      "20 models\n",
      "‚Ä¢\n",
      "3.27k followers\n",
      "Google\n",
      "company\n",
      "‚Ä¢\n",
      "1.01k models\n",
      "‚Ä¢\n",
      "17.9k followers\n",
      "Intel\n",
      "company\n",
      "‚Ä¢\n",
      "205 models\n",
      "‚Ä¢\n",
      "2.69k followers\n",
      "Microsoft\n",
      "company\n",
      "‚Ä¢\n",
      "395 models\n",
      "‚Ä¢\n",
      "13.3k followers\n",
      "Grammarly\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "10 models\n",
      "‚Ä¢\n",
      "166 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "21 models\n",
      "‚Ä¢\n",
      "304 followers\n",
      "Our Open Source\n",
      "We are building the foundation of ML tooling with the community.\n",
      "Transformers\n",
      "146,236\n",
      "State-of-the-art ML for PyTorch, TensorFlow, JAX\n",
      "Diffusers\n",
      "29,572\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Safetensors\n",
      "3,332\n",
      "Safe way to store/distribute neural network weights\n",
      "Hub Python Library\n",
      "2,724\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Tokenizers\n",
      "9,857\n",
      "Fast tokenizers optimized for research & production\n",
      "TRL\n",
      "14,390\n",
      "Train transformers LMs with reinforcement learning\n",
      "Transformers.js\n",
      "13,934\n",
      "State-of-the-art ML running directly in your browser\n",
      "smolagents\n",
      "20,755\n",
      "Smol library to build great agents in Python\n",
      "PEFT\n",
      "18,892\n",
      "Parameter-efficient finetuning for large language models\n",
      "Datasets\n",
      "20,314\n",
      "Access & share datasets for any ML tasks\n",
      "Text Generation Inference\n",
      "10,268\n",
      "Serve language models with TGI optimized toolkit\n",
      "Accelerate\n",
      "8,881\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'ex√©cution\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://huggingface.co\"  # ou \"https://edwarddonner.com\"\n",
    "    output = get_all_details(url)\n",
    "    print(\"\\n\\n=== R√©sultat final ===\\n\")\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d273ddba-4720-47b4-9782-f6a941d798c0",
   "metadata": {},
   "source": [
    "## üß† R√©sum√© visuel\n",
    "\n",
    "```\n",
    "Website(url)\n",
    "   ‚îî‚îÄ‚îÄ .get_contents()     ‚Üí Titre + Texte visible\n",
    "   ‚îî‚îÄ‚îÄ .links              ‚Üí Tous les liens cliquables\n",
    "\n",
    "get_relevant_links_with_llama3(url, links)\n",
    "   ‚îî‚îÄ‚îÄ Envoie √† LLaMA      ‚Üí JSON contenant uniquement les liens utiles\n",
    "\n",
    "get_all_details(url)\n",
    "   ‚îî‚îÄ‚îÄ Website(url)        ‚Üí Landing page\n",
    "   ‚îî‚îÄ‚îÄ get_relevant_links_with_llama3() ‚Üí Filtrage\n",
    "   ‚îî‚îÄ‚îÄ Website(link[\"url\"]) pour chaque page utile ‚Üí Contenu\n",
    "```\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65688855-14ea-4749-99dd-9c9db1280a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt syst√®me (instructions donn√©es au mod√®le)\n",
    "link_system_prompt = (\n",
    "    \"You are provided with a list of links found on a webpage. \"\n",
    "    \"You are able to decide which of the links would be most relevant to include in a brochure about the company, \"\n",
    "    \"such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "    \"You should respond with a JSON object like this example:\\n\"\n",
    "    \"\"\"{\n",
    "  \"links\": [\n",
    "    {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "    {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "  ]\n",
    "}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b85f127-6bc3-4181-a076-df0226e5d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour g√©n√©rer le prompt utilisateur √† partir des liens du site\n",
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url}.\\n\"\n",
    "    user_prompt += \"Please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format.\\n\"\n",
    "    user_prompt += \"Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7efe8a9b-06e7-4c3b-a5ca-d56cd1460b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour appeler Ollama avec les prompts\n",
    "def get_links(url, website):\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.2\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)},\n",
    "        ]\n",
    "    )\n",
    "    content = response['message']['content']\n",
    "\n",
    "    # Extraire JSON dans la r√©ponse brute (au cas o√π il y a du texte autour)\n",
    "    json_match = re.search(r\"\\{[\\s\\S]*\\}\", content)\n",
    "    if json_match:\n",
    "        json_text = json_match.group(0)\n",
    "        try:\n",
    "            return json.loads(json_text)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"JSON decode error:\", e)\n",
    "            print(\"Raw JSON text:\", json_text)\n",
    "    else:\n",
    "        print(\"No JSON found in model response.\")\n",
    "    return {\"links\": []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "324eb2bb-8bc7-4d33-87c7-feb7e7855cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'home page', 'url': 'https://huggingface.co/'},\n",
       "  {'type': 'docs page', 'url': 'https://huggingface.co/docs'},\n",
       "  {'type': 'about page', 'url': 'https://discuss.huggingface.co'},\n",
       "  {'type': 'blog page', 'url': 'https://huggingface.co/blog'},\n",
       "  {'type': 'learn page', 'url': 'https://huggingface.co/learn'},\n",
       "  {'type': 'brand page', 'url': 'https://huggingface.co/brand'}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exemple d'usage (avec ta classe Website d√©finie avant)\n",
    "ed = Website(\"https://huggingface.co\")\n",
    "get_links(\"https://huggingface.co\", ed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "549bd8c7-22bc-4bc9-9c23-0308332b2b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "\n",
    "    # Ici on appelle get_links avec deux arguments : l'url et l'objet Website\n",
    "    website = Website(url)\n",
    "    links = get_links(url, website)  # get_links adapt√© √† Ollama (cf. code pr√©c√©dent)\n",
    "\n",
    "    print(\"Found links:\", links)\n",
    "    for link in links.get(\"links\", []):\n",
    "        result += f\"\\n\\n{link['type'].capitalize()}:\\n\"\n",
    "        page = Website(link[\"url\"])\n",
    "        result += page.get_contents()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e3b9681-d925-4363-b803-d7e96f85f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant that analyzes the contents of several relevant pages from a company website \"\n",
    "    \"and creates a short brochure about the company for prospective customers, investors and recruits. \"\n",
    "    \"Respond in markdown. Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9eb83ecb-5bdc-4ef6-8572-75536189267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += \"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:5000]  # Limite √† 5000 caract√®res pour √©viter un prompt trop long\n",
    "    return user_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c07e6d1-401f-4b33-8708-22fe8ad0d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    user_content = get_brochure_user_prompt(company_name, url)\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.2\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_content}\n",
    "        ]\n",
    "    )\n",
    "    result = response['message']['content']\n",
    "    print(result)  # ou afficher avec un markdown si tu es dans un notebook : display(Markdown(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a6ac2ec-77c6-475b-bce6-65f3ac3881e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'home page', 'url': 'https://huggingface.co/'}, {'type': 'About page', 'url': 'https://huggingface.co/'}, {'type': 'Company page', 'url': 'https://huggingface.co/'}, {'type': 'Careers/Jobs page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'Docs page', 'url': 'https://huggingface.co/docs'}, {'type': 'Blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'Twitter page', 'url': 'https://twitter.com/huggingface'}, {'type': 'LinkedIn page', 'url': 'https://www.linkedin.com/company/huggingface/'}, {'type': 'GitHub page', 'url': 'https://github.com/huggingface'}, {'type': 'Discord server for joining', 'url': 'https://huggingface.co/join/discord'}]}\n",
      "**Welcome to Hugging Face**\n",
      "==========================\n",
      "\n",
      "[Image: A logo of a smiling face, representing the AI community]\n",
      "\n",
      "**Building the Future of Artificial Intelligence**\n",
      "---------------------------------------------\n",
      "\n",
      "At Hugging Face, we are on a mission to create a platform where the machine learning community can collaborate on models, datasets, and applications. Our goal is to accelerate the development of artificial intelligence by providing a comprehensive suite of tools and resources.\n",
      "\n",
      "**What We Do**\n",
      "----------------\n",
      "\n",
      "* Develop open-source software for natural language processing (NLP) and computer vision\n",
      "* Host a vast repository of 1 million+ pre-trained models for various AI tasks\n",
      "* Provide a collaborative platform for researchers, developers, and businesses to work together on AI projects\n",
      "* Offer enterprise-grade security, access controls, and dedicated support for teams\n",
      "\n",
      "**Our Mission**\n",
      "-----------------\n",
      "\n",
      "To build the foundation of machine learning tooling with the community. We strive to make AI accessible to everyone, regardless of their background or expertise.\n",
      "\n",
      "**Community Highlights**\n",
      "------------------------\n",
      "\n",
      "* Over 50,000 organizations are using Hugging Face's platform\n",
      "* Popular models from well-known companies like Meta, Google, Amazon, Intel, and Microsoft are integrated into our platform\n",
      "\n",
      "**Transformers and Technologies**\n",
      "----------------------------------\n",
      "\n",
      "* **Transformers**: State-of-the-art ML for PyTorch, TensorFlow, JAX\n",
      "* **Diffusers**: State-of-the-art Diffusion models in PyTorch\n",
      "* **Safetensors**: Safe way to store/distribute neural network weights\n",
      "* **Hub Python Library**: Python client to interact with the Hugging Face Hub\n",
      "\n",
      "**Join Our Community**\n",
      "-----------------------\n",
      "\n",
      "Sign up for our platform and start exploring AI apps, browsing 1 million+ models, or collaborating on projects with our community. Whether you're a researcher, developer, or business looking to integrate AI into your operations, we invite you to join us.\n",
      "\n",
      "**Get Started Today!**\n",
      "-------------------------\n",
      "\n",
      "Visit our [website](https://huggingface.co/) and explore the possibilities of Hugging Face.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   create_brochure(\"HuggingFace\", \"https://huggingface.co\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d1949dd-3eed-4dfe-a15e-5d1979f370be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display, update_display\n",
    "\n",
    "def stream_brochure(company_name, url):\n",
    "    user_content = get_brochure_user_prompt(company_name, url)\n",
    "\n",
    "    stream = ollama.chat(\n",
    "        model=\"llama3.2\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_content}\n",
    "        ],\n",
    "        stream=True  # Active le streaming\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    \n",
    "    for chunk in stream:\n",
    "        # Chaque chunk est un dictionnaire avec \"message\" > \"content\"\n",
    "        delta = chunk.get(\"message\", {}).get(\"content\", \"\")\n",
    "        if delta:\n",
    "            response += delta\n",
    "            # Nettoyer au besoin, ici je supprime juste les balises de code markdown (optionnel)\n",
    "            cleaned = response.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
    "            update_display(Markdown(cleaned), display_id=display_handle.display_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96e526cc-a623-47fb-a7cf-3a1f81e57f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://huggingface.co/'}, {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'docs page', 'url': 'https://huggingface.co/docs'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'join/discord page', 'url': 'https://huggingface.co/join/discord'}, {'type': 'apply/workable page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'blog page', 'url': 'https://huggingface.co/blog'}, {'type': 'changelog page', 'url': 'https://huggingface.co/changelog'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Hugging Face Brochure\n",
       "\n",
       "## About Us\n",
       "\n",
       "Hugging Face is the AI community building the future. Our platform brings together a collaborative space for machine learning professionals to explore, create, and innovate on models, datasets, and applications.\n",
       "\n",
       "### Our Mission\n",
       "\n",
       "We aim to accelerate the development of artificial intelligence by providing an open-source stack, tools, and resources that foster innovation and progress in the field.\n",
       "\n",
       "## What We Offer\n",
       "\n",
       "*   **Models**: Browse 1M+ pre-trained models across various modalities (text, image, video, audio, and 3D).\n",
       "*   **Datasets**: Access and share datasets for any ML tasks.\n",
       "*   **Spaces**: Collaborate on unlimited public models, datasets, and applications with our platform's advanced infrastructure.\n",
       "\n",
       "### Advanced Solutions\n",
       "\n",
       "For organizations requiring enterprise-grade security, access controls, and dedicated support, we offer:\n",
       "\n",
       "*   **Compute**: Deploy optimized inference endpoints or update your Spaces applications to a GPU in just a few clicks.\n",
       "*   **Enterprise**: Get the most advanced platform for building AI with features like Single Sign-On, Priority Support, Audit Logs, Resource Groups, Private Datasets Viewer.\n",
       "\n",
       "## Our Community\n",
       "\n",
       "Join over 50,000 organizations using Hugging Face, including top companies like Meta, Google, Amazon, Intel, Microsoft, and Grammarly. Explore popular models and datasets, and discover new ones by browsing our platform's trending content.\n",
       "\n",
       "### Transforming the Future of AI\n",
       "\n",
       "At Hugging Face, we're building the foundation for ML tooling with our open-source projects:\n",
       "\n",
       "*   **Transformers**: State-of-the-art ML for PyTorch, TensorFlow, JAX.\n",
       "*   **Diffusers**: State-of-the-art Diffusion models in PyTorch.\n",
       "*   **Safetensors**: Safe way to store/distribute neural network weights.\n",
       "*   **Tokenizers**: Fast tokenizers optimized for research & production.\n",
       "\n",
       "## Join Our Journey\n",
       "\n",
       "Accelerate your ML journey with Hugging Face. Explore our platform, sign up for an account, or get started with our free resources and tutorials today!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25dce9e-877e-4657-a033-d40839845f1c",
   "metadata": {},
   "source": [
    "| Fonction                  | R√¥le                                                                |\n",
    "| ------------------------- | ------------------------------------------------------------------- |\n",
    "| `Website(url)`            | Scrape le contenu texte et les liens d‚Äôun site web.                 |\n",
    "| `get_links_user_prompt()` | Forme un prompt clair avec les liens bruts.                         |\n",
    "| `get_links()`             | Utilise Ollama pour filtrer les liens pertinents (About, Careers‚Ä¶). |\n",
    "| `get_all_details()`       | T√©l√©charge les pages li√©es pertinentes pour en extraire du contenu. |\n",
    "| `create_brochure()`       | G√©n√®re une brochure (markdown) avec LLaMA sans streaming.           |\n",
    "| `stream_brochure()`       | Idem, mais avec mise √† jour en direct (Jupyter Notebook friendly).  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb451fd-9a0d-429c-96df-21e3f2e513c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
